{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "903f3e00",
   "metadata": {},
   "source": [
    "# Playing around with Flux1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14227db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install \"gguf[gui]\" diffusers transformers accelerate bitsandbytes sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ba99ba",
   "metadata": {},
   "source": [
    "## Select Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7922f4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cuda\n"
     ]
    }
   ],
   "source": [
    "# choose device: prefer CUDA, then MPS, then CPU\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "except Exception:\n",
    "    cuda_available = False\n",
    "\n",
    "mps_available = False\n",
    "try:\n",
    "    mps_backend = getattr(torch.backends, \"mps\", None)\n",
    "    mps_available = mps_backend is not None and mps_backend.is_available()\n",
    "except Exception:\n",
    "    mps_available = False\n",
    "\n",
    "if cuda_available:\n",
    "    device = torch.device(\"cuda\")\n",
    "elif mps_available:\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Selected device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0873fdb",
   "metadata": {},
   "source": [
    "## FIXME: Below crashes Jupyter due to OOM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616b8296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import FluxPipeline, FluxTransformer2DModel, GGUFQuantizationConfig\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "#torch.mps.set_per_process_memory_fraction(0.0)\n",
    "\n",
    "def flush():\n",
    "    gc.collect()\n",
    "    #torch.mps.empty_cache()\n",
    "    gc.collect()\n",
    "    #torch.mps.empty_cache()\n",
    "\n",
    "prompt = \"a moonim dressed as a knight, riding a horse towards a medieval castle\"\n",
    "\n",
    "ckpt_id = \"black-forest-labs/FLUX.1-dev\"\n",
    "\n",
    "pipeline = FluxPipeline.from_pretrained(\n",
    "    ckpt_id,\n",
    "    transformer=None,\n",
    "    vae=None,\n",
    "    dtype=torch.bfloat16,\n",
    ").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(\"Encoding prompts.\")\n",
    "    prompt_embeds, pooled_prompt_embeds, text_ids = pipeline.encode_prompt(\n",
    "        prompt=prompt, prompt_2=prompt, max_sequence_length=256\n",
    "    )\n",
    "\n",
    "\n",
    "del pipeline\n",
    "flush()\n",
    "\n",
    "#ckpt_path = \"https://huggingface.co/city96/FLUX.1-dev-gguf/blob/main/flux1-dev-Q8_0.gguf\"\n",
    "ckpt_path = \"/home/sral/Downloads/flux1-dev-Q8_0.gguf\"\n",
    "\n",
    "transformer = FluxTransformer2DModel.from_single_file(\n",
    "    ckpt_path,\n",
    "    quantization_config=GGUFQuantizationConfig(compute_dtype=torch.bfloat16),\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "pipeline = FluxPipeline.from_pretrained(\n",
    "    \"black-forest-labs/FLUX.1-dev\",\n",
    "    text_encoder=None,\n",
    "    text_encoder_2=None,\n",
    "    tokenizer=None,\n",
    "    tokenizer_2=None,\n",
    "    transformer=transformer,\n",
    "    dtype=torch.bfloat16,\n",
    ").to(device)\n",
    "\n",
    "print(\"Running denoising.\")\n",
    "height, width = 1024, 1024\n",
    "# No need to wrap it up under `torch.no_grad()` as pipeline call method\n",
    "# is already wrapped under that.\n",
    "images = pipeline(\n",
    "    prompt_embeds=prompt_embeds,\n",
    "    pooled_prompt_embeds=pooled_prompt_embeds,\n",
    "    num_inference_steps=15,\n",
    "    guidance_scale=5.0,\n",
    "    height=height,\n",
    "    width=width,\n",
    "    generator=torch.Generator(device).manual_seed(42)\n",
    ").images[0]\n",
    "\n",
    "images.save(\"compile_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0228ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
