{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec9a8957",
   "metadata": {},
   "source": [
    "# Notebook with random quick tests.\n",
    "\n",
    "RS20250619"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0915645",
   "metadata": {},
   "source": [
    "## Tool calling with Mistral and Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c18c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Ollama Tool Calling\n",
      "========================================\n",
      "User: What's the weather like in New York?\n",
      "Assistant: I need to use some tools to help you.\n",
      "Calling tool: get_weather\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 167\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m40\u001b[39m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Test weather tool\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m \u001b[43mchat_with_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms the weather like in New York?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# Test calculator tool\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 140\u001b[0m, in \u001b[0;36mchat_with_tools\u001b[0;34m(prompt, model_name)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Add tool results\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tool_result \u001b[38;5;129;01min\u001b[39;00m tool_results:\n\u001b[1;32m    137\u001b[0m     messages\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: json\u001b[38;5;241m.\u001b[39mdumps(tool_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m--> 140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_call_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mtool_result\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    141\u001b[0m     })\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Call the model again with tool results\u001b[39;00m\n\u001b[1;32m    144\u001b[0m final_payload \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_name,\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    149\u001b[0m }\n",
      "\u001b[0;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define your custom tools\n",
    "def get_weather(location):\n",
    "    \"\"\"Get weather information for a location (mock implementation)\"\"\"\n",
    "    # This is a mock function - in reality you'd call a weather API\n",
    "    weather_data = {\n",
    "        \"New York\": {\"temperature\": \"22°C\", \"condition\": \"Sunny\"},\n",
    "        \"London\": {\"temperature\": \"15°C\", \"condition\": \"Cloudy\"},\n",
    "        \"Tokyo\": {\"temperature\": \"28°C\", \"condition\": \"Rainy\"}\n",
    "    }\n",
    "    return weather_data.get(location, {\"temperature\": \"Unknown\", \"condition\": \"Unknown\"})\n",
    "\n",
    "def calculate(expression):\n",
    "    \"\"\"Safely calculate a mathematical expression\"\"\"\n",
    "    try:\n",
    "        # Only allow safe mathematical operations\n",
    "        allowed_chars = set('0123456789+-*/.() ')\n",
    "        if all(c in allowed_chars for c in expression):\n",
    "            result = eval(expression)\n",
    "            return {\"result\": result}\n",
    "        else:\n",
    "            return {\"error\": \"Invalid characters in expression\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Tool definitions for the model\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get current weather information for a specific location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city or location to get weather for\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"calculate\",\n",
    "            \"description\": \"Calculate a mathematical expression\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"expression\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Mathematical expression to calculate (e.g., '2 + 2', '10 * 5')\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"expression\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "def call_ollama_with_tools(prompt, tools, model_name=\"mistral\"):\n",
    "    \"\"\"Call Ollama with tool calling capability\"\"\"\n",
    "    \n",
    "    url = \"http://localhost:11434/api/chat\"\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"tools\": tools,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error calling Ollama: {e}\")\n",
    "        return None\n",
    "\n",
    "def execute_tool_call(tool_call):\n",
    "    \"\"\"Execute a tool call and return the result\"\"\"\n",
    "    function_name = tool_call[\"function\"][\"name\"]\n",
    "    arguments = tool_call[\"function\"][\"arguments\"]\n",
    "    \n",
    "    if function_name == \"get_weather\":\n",
    "        return get_weather(arguments[\"location\"])\n",
    "    elif function_name == \"calculate\":\n",
    "        return calculate(arguments[\"expression\"])\n",
    "    else:\n",
    "        return {\"error\": f\"Unknown function: {function_name}\"}\n",
    "\n",
    "def chat_with_tools(prompt, model_name=\"mistral\"):\n",
    "    \"\"\"Complete chat interaction with tool calling\"\"\"\n",
    "    print(f\"User: {prompt}\")\n",
    "    \n",
    "    # Initial call to the model\n",
    "    response = call_ollama_with_tools(prompt, tools, model_name)\n",
    "    \n",
    "    if not response:\n",
    "        return\n",
    "    \n",
    "    message = response[\"message\"]\n",
    "    \n",
    "    # Check if the model wants to call any tools\n",
    "    if \"tool_calls\" in message and message[\"tool_calls\"]:\n",
    "        print(f\"Assistant: I need to use some tools to help you.\")\n",
    "        \n",
    "        # Execute each tool call\n",
    "        tool_results = []\n",
    "        \n",
    "        for tool_call in message[\"tool_calls\"]:\n",
    "            print(f\"Calling tool: {tool_call['function']['name']}\")\n",
    "            result = execute_tool_call(tool_call)\n",
    "            id += 1\n",
    "            tool_results.append({\n",
    "                \"call\": tool_call,\n",
    "                \"result\": result,\n",
    "                \"id\": id\n",
    "            })\n",
    "        \n",
    "        # Make a follow-up call with tool results\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": message.get(\"content\", \"\"), \"tool_calls\": message[\"tool_calls\"]},\n",
    "        ]\n",
    "        \n",
    "        # Add tool results\n",
    "        for tool_result in tool_results:\n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": json.dumps(tool_result[\"result\"]),\n",
    "                \"tool_call_id\": tool_result[\"call\"][\"id\"]\n",
    "            })\n",
    "        \n",
    "        # Call the model again with tool results\n",
    "        final_payload = {\n",
    "            \"model\": model_name,\n",
    "            \"messages\": messages,\n",
    "            \"tools\": tools,\n",
    "            \"stream\": False\n",
    "        }\n",
    "        \n",
    "        final_response = requests.post(\"http://localhost:11434/api/chat\", json=final_payload)\n",
    "        if final_response.status_code == 200:\n",
    "            final_message = final_response.json()[\"message\"]\n",
    "            print(f\"Assistant: {final_message['content']}\")\n",
    "        else:\n",
    "            print(\"Error in follow-up call\")\n",
    "    else:\n",
    "        # No tools needed, just return the response\n",
    "        print(f\"Assistant: {message['content']}\")\n",
    "\n",
    "# Test the tool calling functionality\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Testing Ollama Tool Calling\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Test weather tool\n",
    "    chat_with_tools(\"What's the weather like in New York?\")\n",
    "    print()\n",
    "    \n",
    "    # Test calculator tool\n",
    "    chat_with_tools(\"What is 15 * 7 + 23?\")\n",
    "    print()\n",
    "    \n",
    "    # Test multiple tools in one query\n",
    "    chat_with_tools(\"What's the weather in London and what is 100 divided by 4?\")\n",
    "    print()\n",
    "    \n",
    "    # Test without tools\n",
    "    chat_with_tools(\"Tell me a joke about programming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2e7238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
